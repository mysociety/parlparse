#!/usr/bin/env python

# Grabs the json files for policy voted from public whip

import os
import re
import requests

from bs4 import BeautifulSoup

base_url = 'https://www.publicwhip.org.uk/data/popolo/'
headers = {
    'User-Agent': 'TheyWorkForYou/1.0',
}

OUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../../parldata/scrapedjson/policy-motions')


all_json = requests.get(base_url, headers=headers).content
soup = BeautifulSoup(all_json, 'lxml')
json_files = soup.find_all( href=re.compile("json") )

for json in json_files:
    url = "%s%s" % ( base_url, json['href'] )
    out = "%s/%s" % ( OUT_DIR, json['href'] )
    data = requests.get(url, headers=headers).content
    open(out, 'w').write(data)
